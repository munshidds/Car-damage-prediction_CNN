{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Traning by using MobileNet**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "70jNrgCgnebX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import tensorflow into colab\n",
        "import tensorflow as tf\n",
        "print(\"TF version:\",tf.__version__)\n",
        "#Check for GPU availability\n",
        "print(\"GPU\", \"available (YESSSSS!!!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available\")"
      ],
      "metadata": {
        "id": "ICqHaHo5QsCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#chekking total training images\n",
        "dam_path='/content/drive/MyDrive/colab_notes/car_damage_vision/car_damage_data/training/00-damage'\n",
        "not_dam_path='/content/drive/MyDrive/colab_notes/car_damage_vision/car_damage_data/training/01-whole'\n",
        "total_training_img=(len(dam_path)+ len(not_dam_path))\n",
        "print(f'nomber of total training image :{total_training_img}')\n",
        "print(f'nomber of not damaged image : {len(not_dam_path)}')\n",
        "print(f'nomber of damaged image :{len(dam_path)}')"
      ],
      "metadata": {
        "id": "kqozreXbQr9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        " \n",
        "# creating the bar plot\n",
        "plt.bar(len(dam_path), len(dam_path), color ='maroon',\n",
        "        width = 0.4)\n",
        "plt.bar(len(not_dam_path), len(not_dam_path), color ='yellow',\n",
        "        width = 0.4)\n",
        "plt.xlabel(\"not damaged images\")\n",
        "plt.ylabel(\"damaged images\")\n",
        "plt.title(\"cound of training images\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "buiRICmeQr7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# just showing a damaged car image\n",
        "from IPython.display import Image\n",
        "Image('/content/drive/MyDrive/colab_notes/car_damage_vision/car_damage_data/training/00-damage/0036.JPEG')"
      ],
      "metadata": {
        "id": "fBuyUi3-Qr4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade imutils"
      ],
      "metadata": {
        "id": "ucy193_2QHS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install imutils. Released: Jan 15, 2021. A series of convenience functions to make basic\n",
        "# image processing functions such as translation, rotation, resizing, skeletonization, displaying \n",
        "# Matplotlib images, sorting contours, detecting edges, and much more easier with OpenCV and both \n",
        "# Python 2.7 and Python 3.\n",
        "# pip install --upgrade imutils"
      ],
      "metadata": {
        "id": "xIur65_bHrbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# necessary imports\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# Keras ImageDataGenerator is a gem! It lets you augment your images in real-time while your\n",
        "# model is still training! You can apply any random transformations on each training image as \n",
        "# it is passed to the model. This will not only make your model robust but will also save up on \n",
        "# the overhead memory!\n",
        "print('Image Augmentation on the fly using Keras ImageDataGenerator!')\n",
        "import cv2\n",
        "im = cv2.imread('/content/drive/MyDrive/colab_notes/car_damage_vision/Screenshot (22).png')\n",
        "# im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(im)\n",
        "\n",
        "\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "# MobileNet is a CNN architecture that is much faster as well as a smaller model that makes use \n",
        "# of a new kind of convolutional layer, known as Depthwise Separable convolution. Because of the \n",
        "# small size of the model, these models are considered very useful to be implemented on mobile \n",
        "# and embedded devices.\n",
        "\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "# mobilenet_v2. preprocess_input will scale input pixels between -1 and 1. Arguments. \n",
        "# input_shape: Optional shape tuple, to be specified if you would like to use a model with \n",
        "# an input image resolution that is not (224, 224, 3). It should have exactly 3 inputs channels (224, 224, 3).\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Sp8nEM4kmRRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the initial learning rate, number of epochs to train for,\n",
        "# and batch size\n",
        "EPOCHS = 50\n",
        "BS = 64\n",
        "\n",
        "Training_data_path = r\"/content/drive/MyDrive/colab_notes/car_damage_vision/car_damage_data/training\"\n",
        "Validation_data_path=r\"/content/drive/MyDrive/colab_notes/car_damage_vision/car_damage_data/validation\"\n",
        "CATEGORIES = [\"00-damage\", \"01-whole\"]\n",
        "\n",
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading images...\")\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for category in CATEGORIES:\n",
        "    path = os.path.join(Training_data_path, category)\n",
        "    for img in os.listdir(path):\n",
        "    \timg_path = os.path.join(path, img)\n",
        "    \timage = load_img(img_path, target_size=(224, 224))\n",
        "    \timage = img_to_array(image)\n",
        "    \timage = preprocess_input(image)\n",
        "\n",
        "    \tdata.append(image)\n",
        "    \tlabels.append(category)\n",
        "\n",
        "\n",
        "for category in CATEGORIES:\n",
        "    path = os.path.join(Validation_data_path, category)\n",
        "    for img in os.listdir(path):\n",
        "    \timg_path = os.path.join(path, img)\n",
        "    \timage = load_img(img_path, target_size=(224, 224))\n",
        "    \timage = img_to_array(image)\n",
        "    \timage = preprocess_input(image)\n",
        "\n",
        "    \tdata.append(image)\n",
        "    \tlabels.append(category)\n",
        "        \n",
        "# perform one-hot encoding on the labels\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels)\n",
        "\n",
        "data = np.array(data, dtype=\"float32\")\n",
        "labels = np.array(labels)\n",
        "\n",
        "\n",
        "\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "\ttest_size=0.20, stratify=labels, random_state=42)\n",
        "\n",
        "# construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=20,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9_D2YVurmdDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# load the MobileNetV2 network, ensuring the head FC layer sets are\n",
        "# left off\n",
        "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "headModel = MaxPooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
        "\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "# loop over all layers in the base model and freeze them so they will\n",
        "# *not* be updated during the first training process\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "# compile our model\n",
        "INIT_LR = 1e-5\n",
        "print(\"[INFO] compiling model...\")\n",
        "# lr=INIT_LR, decay=INIT_LR / EPOCHS\n",
        "opt = Adam()\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# train the head of the network\n",
        "print(\"[INFO] training head...\")\n",
        "H = model.fit(\n",
        "\taug.flow(trainX, trainY, batch_size=BS),\n",
        "\tsteps_per_epoch=len(trainX) // BS,\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tvalidation_steps=len(testX) // BS,\n",
        "\tepochs=EPOCHS)\n",
        "\n",
        "# make predictions on the testing set\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = model.predict(testX, batch_size=BS)\n",
        "\n",
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "# show a nicely formatted classification report\n",
        "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
        "\ttarget_names=lb.classes_))\n",
        "\n",
        "# serialize the model to disk\n",
        "print(\"[INFO] saving mask detector model...\")\n",
        "model.save(\"MobileNet_Car_detection.model\", save_format=\"h5\")\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "N = EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"MobileNet.png\")"
      ],
      "metadata": {
        "id": "ebqz9H6RABQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Lnuw45MpnFeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models    \n",
        "MobileNet = models.load_model(\"MobileNet_Car_detection.model\")"
      ],
      "metadata": {
        "id": "aSE70fkpnHfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testURL=\"/content/drive/MyDrive/colab_notes/car_damage_vision/car_damage_data/validation\"\n",
        "damage_test_url=\"/content/drive/MyDrive/colab_notes/car_damage_vision/car_damage_data/validation/00-damage\"\n",
        "whole_test_url=\"/content/drive/MyDrive/colab_notes/car_damage_vision/car_damage_data/validation/01-whole\"\n",
        "damage_img = [f'{damage_test_url}/{i}' for i in os.listdir(damage_test_url)]\n",
        "whole_img=[f'{whole_test_url}/{i}' for i in os.listdir(whole_test_url)]\n",
        "total_img=damage_img+whole_img"
      ],
      "metadata": {
        "id": "dWA8G6nvnSEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "img_path = \"/content/drive/MyDrive/colab_notes/car_damage_vision/car_damage_data/validation/01-whole/0008.jpg\"\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_batch = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "\n",
        "im = cv2.imread(img_path)\n",
        "im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(im)\n",
        "\n",
        "pred=MobileNet.predict(img_batch)\n",
        "print(\"Car is Damaged: \"+str(pred[0][0])+\", Car is not Damaged: \"+str(pred[0][1]))\n",
        "if pred[0][0]<pred[0][1]:\n",
        "    print(\"The car is not damaged\")\n",
        "else:\n",
        "    print(\"The car is damaged\")"
      ],
      "metadata": {
        "id": "pa3DioPunTv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "img_path = \"/content/drive/MyDrive/colab_notes/car_damage_vision/car_damage_data/validation/00-damage/0017.JPEG\"\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_batch = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "\n",
        "im = cv2.imread(img_path)\n",
        "im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(im)\n",
        "\n",
        "pred=MobileNet.predict(img_batch)\n",
        "print(\"Car is Damaged: \"+str(pred[0][0])+\", Car is not Damaged: \"+str(pred[0][1]))\n",
        "if pred[0][0]<pred[0][1]:\n",
        "    print(\"The car is not damaged\")\n",
        "else:\n",
        "    print(\"The car is damaged\")"
      ],
      "metadata": {
        "id": "yNqhAACPpnbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Mj4NI4utH2R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}